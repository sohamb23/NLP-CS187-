{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Please do not change this cell because some hidden tests might depend on it.\n",
    "import os\n",
    "\n",
    "# Otter grader does not handle ! commands well, so we define and use our\n",
    "# own function to execute shell commands.\n",
    "def shell(commands, warn=True):\n",
    "    \"\"\"Executes the string `commands` as a sequence of shell commands.\n",
    "     \n",
    "       Prints the result to stdout and returns the exit status. \n",
    "       Provides a printed warning on non-zero exit status unless `warn` \n",
    "       flag is unset.\n",
    "    \"\"\"\n",
    "    file = os.popen(commands)\n",
    "    print (file.read().rstrip('\\n'))\n",
    "    exit_status = file.close()\n",
    "    if warn and exit_status != None:\n",
    "        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n",
    "    return exit_status\n",
    "\n",
    "shell(\"\"\"\n",
    "ls requirements.txt >/dev/null 2>&1\n",
    "if [ ! $? = 0 ]; then\n",
    " rm -rf .tmp\n",
    " git clone https://github.com/cs187-2021/lab1-2.git .tmp\n",
    " mv .tmp/tests ./\n",
    " mv .tmp/requirements.txt ./\n",
    " rm -rf .tmp\n",
    "fi\n",
    "pip install -q -r requirements.txt\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0e98b3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_for_latex"
    ]
   },
   "source": [
    "# CS187\n",
    "## Lab 1-2 — Text classification and evaluation methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this lab, you should be able to\n",
    "\n",
    "* Understand the distinction between training and test corpora, and why both are needed;\n",
    "* Understand the role of gold labels;\n",
    "* Implement a majority class baseline as a benchmark to compare other methods;\n",
    "* Implement nearest neighbor classification, and understand the role of distance metrics in its operation;\n",
    "* Compare multiple methods for acccuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New bits of Python used for the first time in the _solution set_ for this lab, and which you may therefore find useful, include\n",
    "\n",
    "* [`collections.Counter`](https://docs.python.org/3/library/collections.html#collections.Counter)\n",
    "* [`collections.Counter.most_common`](https://docs.python.org/3/library/collections.html#collections.Counter.most_common)\n",
    "* [`torch.float`](https://pytorch.org/docs/stable/tensors.html)\n",
    "* [`torch.Tensor.type`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html?highlight=torch%20tensor%20type#torch.Tensor.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation – Loading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Please do not change these imports because some hidden tests might depend on them.\n",
    "# You can add a cell below if you need to import anything else.\n",
    "import collections\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Federalist Papers\n",
    "\n",
    "<img src=\"https://github.com/nlp-course/data/raw/master/Federalist/federalist.jpg\" width=150 align=right />\n",
    "\n",
    "The _Federalist_ papers is a collection of 85 essays written pseudonymously by Alexander Hamilton, John Jay, and James Madison following the Constitutional Convention of 1787, promoting the ratification of the nascent United States Constitution.\n",
    "\n",
    "The authorship of many of the individual papers has been well established and acknowledged by the various authors, but a number of the papers have been contentious, with both Madison and Hamilton as possible authors. Determining the authorship of these disputed papers is a classic text classification problem, and one that has received great attention. The seminal work on the problem is that of [Mosteller and Wallace](http://www.historyofinformation.com/detail.php?entryid=4799), who applied then-novel statistical methods to the problem. In this lab, we'll use the _Federalist_ data to experiment with some of the ideas about distance metrics and classification methods that you've read about. (It's also an excuse to make some points about proper testing methodology.)\n",
    "\n",
    "Mosteller and Wallace used the frequencies of various words in the papers as the raw data for determining authorship. We've provided access to a heavily pre-digested version of this data. (If you're interested, you can find the raw data – all 85 papers – and the notebook used to generate the pre-digested data in the [course `data` github repository](https://github.com/nlp-course/data).)\n",
    "\n",
    "Start by evaluating the cells below to load the data and view a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% [                                                                              ]     0 / 16713\r",
      " 49% [......................................                                        ]  8192 / 16713\r",
      " 98% [............................................................................  ] 16384 / 16713\r",
      "100% [..............................................................................] 16713 / 16713"
     ]
    }
   ],
   "source": [
    "# Retrieve the Federalist data\n",
    "os.makedirs('data', exist_ok=True)\n",
    "wget.download('https://github.com/nlp-course/data/raw/master/Federalist/federalist_data.json', out='data/')\n",
    "# Read the json data into a data structure\n",
    "with open('data/federalist_data.json', 'r') as fin:\n",
    "    dataset = json.load(fin)\n",
    "# Convert counts to tensors of floats\n",
    "for example in dataset:\n",
    "    example['counts'] = torch.tensor(example['counts']).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers in the dataset: 85\n",
      "Some examples:\n",
      "[{'authors': 'Hamilton',\n",
      "  'counts': tensor([9., 6., 2., 0.]),\n",
      "  'number': '1',\n",
      "  'title': 'General Introduction'},\n",
      " {'authors': 'Jay',\n",
      "  'counts': tensor([8., 1., 0., 0.]),\n",
      "  'number': '2',\n",
      "  'title': 'Concerning Dangers from Foreign Force and Influence'},\n",
      " {'authors': 'Jay',\n",
      "  'counts': tensor([6., 0., 1., 0.]),\n",
      "  'number': '3',\n",
      "  'title': 'The Same Subject Continued: Concerning Dangers from Foreign Force '\n",
      "           'and Influence'}]\n"
     ]
    }
   ],
   "source": [
    "# View a sample of the data\n",
    "print(f\"Number of papers in the dataset: {len(dataset)}\")\n",
    "print(\"Some examples:\")\n",
    "pprint(dataset[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see above that the dataset is a list of *examples*, one for each paper, each a dictionary providing the paper number, its title and author(s), and the raw counts for a few important words in the papers. From the last lab, you'll recognize the `counts` field as a bag-of-words representation of the document. The `counts` field is the document representation that we will be wanting to classify, and the `authors` field contains the pertinent class label for each example. \n",
    "\n",
    "For your reference, here are the words that were used to derive the counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['on', 'upon', 'there', 'whilst']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus in the first example paper, *Federalist 1*, there were 9 tokens of \"on\", 6 of \"upon\", 2 of \"there\", and none of \"whilst\". \n",
    "\n",
    "The `authors` field takes on various values. Here's a table of the frequency of each of the values. (This will come in handy later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict_items'>\n",
      "dict_items([('Hamilton', 51), ('Jay', 5), ('Madison', 15), ('Hamilton and Madison', 3), ('Hamilton or Madison', 11)])\n",
      " 51 (60.000%) Hamilton\n",
      "<class 'dict_items'>\n",
      "dict_items([('Hamilton', 51), ('Jay', 5), ('Madison', 15), ('Hamilton and Madison', 3), ('Hamilton or Madison', 11)])\n",
      "  5 (5.882%) Jay\n",
      "<class 'dict_items'>\n",
      "dict_items([('Hamilton', 51), ('Jay', 5), ('Madison', 15), ('Hamilton and Madison', 3), ('Hamilton or Madison', 11)])\n",
      " 15 (17.647%) Madison\n",
      "<class 'dict_items'>\n",
      "dict_items([('Hamilton', 51), ('Jay', 5), ('Madison', 15), ('Hamilton and Madison', 3), ('Hamilton or Madison', 11)])\n",
      "  3 (3.529%) Hamilton and Madison\n",
      "<class 'dict_items'>\n",
      "dict_items([('Hamilton', 51), ('Jay', 5), ('Madison', 15), ('Hamilton and Madison', 3), ('Hamilton or Madison', 11)])\n",
      " 11 (12.941%) Hamilton or Madison\n"
     ]
    }
   ],
   "source": [
    "# Generate a table of the number of papers by each author label\n",
    "cnt = collections.Counter(map(lambda ex: ex['authors'],\n",
    "                              dataset))\n",
    "for author, count in cnt.items():\n",
    "    print(type(cnt.items()))\n",
    "    print(cnt.items())\n",
    "    print(f\"{count:3d} ({100.0*count/len(dataset):.3f}%) {author}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, some of the papers are of known authorship by one of Madison or Hamilton. We can use these as training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'authors': 'Hamilton',\n",
       "  'counts': tensor([9., 6., 2., 0.]),\n",
       "  'number': '1',\n",
       "  'title': 'General Introduction'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([2., 4., 7., 0.]),\n",
       "  'number': '6',\n",
       "  'title': 'Concerning Dangers from Dissensions Between the States'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([13., 11.,  9.,  0.]),\n",
       "  'number': '7',\n",
       "  'title': 'The Same Subject Continued: Concerning Dangers from Dissensions Between the States'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([11.,  3.,  1.,  0.]),\n",
       "  'number': '8',\n",
       "  'title': 'The Consequences of Hostilities Between the States'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([9., 4., 3., 0.]),\n",
       "  'number': '9',\n",
       "  'title': 'The Union as a Safeguard Against Domestic Faction and Insurrection'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([18.,  0.,  4.,  0.]),\n",
       "  'number': '10',\n",
       "  'title': 'The Same Subject Continued: The Union as a Safeguard Against Domestic Faction and Insurrection'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([5., 6., 5., 0.]),\n",
       "  'number': '11',\n",
       "  'title': 'The Utility of the Union in Respect to Commercial Relations and a Navy'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([12.,  7.,  9.,  0.]),\n",
       "  'number': '12',\n",
       "  'title': 'The Utility of the Union in Respect to Revenue'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([3., 2., 9., 0.]),\n",
       "  'number': '13',\n",
       "  'title': 'Advantage of the Union in Respect to Economy in Government'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([17.,  0.,  0.,  1.]),\n",
       "  'number': '14',\n",
       "  'title': 'Objections to the Proposed Constitution from Extent of Territory Answered'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([10., 10., 16.,  0.]),\n",
       "  'number': '15',\n",
       "  'title': 'The Insufficiency of the Present Confederation to Preserve the Union'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([4., 6., 4., 0.]),\n",
       "  'number': '16',\n",
       "  'title': 'The Same Subject Continued: The Insufficiency of the Present Confederation to Preserve the Union'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([2., 6., 3., 0.]),\n",
       "  'number': '17',\n",
       "  'title': 'The Same Subject Continued: The Insufficiency of the Present Confederation to Preserve the Union'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([6., 6., 7., 0.]),\n",
       "  'number': '21',\n",
       "  'title': 'Other Defects of the Present Confederation'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([ 9., 13., 14.,  0.]),\n",
       "  'number': '22',\n",
       "  'title': 'The Same Subject Continued: Other Defects of the Present Confederation'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([2., 7., 4., 0.]),\n",
       "  'number': '23',\n",
       "  'title': 'The Necessity of a Government as Energetic as the One Proposed to the Preservation of the Union'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([11.,  7.,  6.,  0.]),\n",
       "  'number': '24',\n",
       "  'title': 'The Powers Necessary to the Common Defense Further Considered'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([11.,  2.,  1.,  0.]),\n",
       "  'number': '25',\n",
       "  'title': 'The Same Subject Continued: The Powers Necessary to the Common Defense Further Considered'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([7., 6., 8., 0.]),\n",
       "  'number': '26',\n",
       "  'title': 'The Idea of Restraining the Legislative Authority in Regard to the Common Defense Considered'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([4., 4., 8., 0.]),\n",
       "  'number': '27',\n",
       "  'title': 'The Same Subject Continued: The Idea of Restraining the Legislative Authority in Regard to the Common Defense Considered'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([1., 3., 7., 0.]),\n",
       "  'number': '28',\n",
       "  'title': 'The Same Subject Continued: The Idea of Restraining the Legislative Authority in Regard to the Common Defense Considered'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([ 3., 10., 12.,  0.]),\n",
       "  'number': '29',\n",
       "  'title': 'Concerning the Militia'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([ 8., 13.,  5.,  0.]),\n",
       "  'number': '30',\n",
       "  'title': 'Concerning the General Power of Taxation'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([ 5., 13.,  6.,  0.]),\n",
       "  'number': '31',\n",
       "  'title': 'The Same Subject Continued: Concerning the Power of Taxation'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([14.,  2.,  8.,  0.]),\n",
       "  'number': '32',\n",
       "  'title': 'The Same Subject Continued: Concerning the Power of Taxation'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([5., 9., 2., 0.]),\n",
       "  'number': '33',\n",
       "  'title': 'The Same Subject Continued: Concerning the Power of Taxation'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([11., 10.,  9.,  0.]),\n",
       "  'number': '34',\n",
       "  'title': 'The Same Subject Continued: Concerning the Power of Taxation'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([8., 9., 4., 0.]),\n",
       "  'number': '35',\n",
       "  'title': 'The Same Subject Continued: Concerning the Power of Taxation'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([ 6.,  6., 17.,  0.]),\n",
       "  'number': '36',\n",
       "  'title': 'The Same Subject Continued: Concerning the Power of Taxation'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([19.,  1.,  2.,  1.]),\n",
       "  'number': '37',\n",
       "  'title': 'Concerning the Difficulties of the Convention in Devising a Proper Form of Government'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([15.,  4.,  3.,  2.]),\n",
       "  'number': '38',\n",
       "  'title': 'Incoherence of the Objections to the New Plan Exposed'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([23.,  0.,  0.,  0.]),\n",
       "  'number': '39',\n",
       "  'title': 'Conformity of the Plan to Republican Principles'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([13.,  0.,  3.,  0.]),\n",
       "  'number': '40',\n",
       "  'title': 'The Powers of the Convention to Form a Mixed Government Examined and Sustained'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([27.,  0.,  1.,  1.]),\n",
       "  'number': '41',\n",
       "  'title': 'General View of the Powers Conferred by the Constitution'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([22.,  2.,  3.,  0.]),\n",
       "  'number': '42',\n",
       "  'title': 'The Powers Conferred by the Constitution Further Considered'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([33.,  0.,  2.,  1.]),\n",
       "  'number': '43',\n",
       "  'title': 'The Same Subject Continued: The Powers Conferred by the Constitution Further Considered'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([29.,  0.,  4.,  2.]),\n",
       "  'number': '44',\n",
       "  'title': 'Restrictions on the Authority of the Several States'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([9., 0., 3., 2.]),\n",
       "  'number': '45',\n",
       "  'title': 'The Alleged Danger From the Powers of the Union to the State Governments Considered'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([31.,  0.,  0.,  2.]),\n",
       "  'number': '46',\n",
       "  'title': 'The Influence of the State and Federal Governments Compared'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([20.,  0.,  3.,  0.]),\n",
       "  'number': '47',\n",
       "  'title': 'The Particular Structure of the New Government and Distribution of Power Among Its Different Parts'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([15.,  0.,  2.,  0.]),\n",
       "  'number': '48',\n",
       "  'title': 'These Departments Should Not Be So Far Separated as to Have No Constitutional Control Over Each Other'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': tensor([17.,  0.,  2.,  0.]),\n",
       "  'number': '58',\n",
       "  'title': 'Objection that the Number of Members Will Not Be Augmented as the Progress of Population Demands Considered'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([6., 3., 7., 0.]),\n",
       "  'number': '59',\n",
       "  'title': 'Concerning the Power of Congress to Regulate the Election of Members'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([6., 8., 8., 0.]),\n",
       "  'number': '60',\n",
       "  'title': 'The Same Subject Continued: Concerning the Power of Congress to Regulate the Election of Members'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([6., 3., 5., 0.]),\n",
       "  'number': '61',\n",
       "  'title': 'The Same Subject Continued: Concerning the Power of Congress to Regulate the Election of Members'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([ 5., 10.,  5.,  0.]),\n",
       "  'number': '65',\n",
       "  'title': 'The Powers of the Senate Continued'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([ 7., 11.,  5.,  0.]),\n",
       "  'number': '66',\n",
       "  'title': 'Objections to the Power of the Senate To Set as a Court for Impeachments Further Considered'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([3., 6., 2., 0.]),\n",
       "  'number': '67',\n",
       "  'title': 'The Executive Department'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([3., 2., 1., 0.]),\n",
       "  'number': '68',\n",
       "  'title': 'The Mode of Electing the President'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([ 6., 12.,  9.,  0.]),\n",
       "  'number': '69',\n",
       "  'title': 'The Real Character of the Executive'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([28., 10., 22.,  0.]),\n",
       "  'number': '70',\n",
       "  'title': 'The Executive Department Further Considered'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([7., 3., 2., 0.]),\n",
       "  'number': '71',\n",
       "  'title': 'The Duration in Office of the Executive'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([6., 5., 8., 0.]),\n",
       "  'number': '72',\n",
       "  'title': 'The Same Subject Continued, and Re-Eligibility of the Executive Considered'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([ 5., 13.,  5.,  0.]),\n",
       "  'number': '73',\n",
       "  'title': 'The Provision for Support of the Executive, and the Veto Power'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([3., 3., 4., 0.]),\n",
       "  'number': '74',\n",
       "  'title': 'The Command of the Military and Naval Forces, and the Pardoning Power of the Executive'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([5., 5., 3., 0.]),\n",
       "  'number': '75',\n",
       "  'title': 'The Treaty Making Power of the Executive'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([ 4., 10.,  7.,  0.]),\n",
       "  'number': '76',\n",
       "  'title': 'The Appointing Power of the Executive'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([ 3., 10.,  3.,  0.]),\n",
       "  'number': '77',\n",
       "  'title': 'The Appointing Power Continued and Other Powers of the Executive Considered'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([10.,  8., 10.,  0.]),\n",
       "  'number': '78',\n",
       "  'title': 'The Judiciary Department'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([5., 2., 3., 0.]),\n",
       "  'number': '79',\n",
       "  'title': 'The Judiciary Continued'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([9., 6., 7., 0.]),\n",
       "  'number': '80',\n",
       "  'title': 'The Powers of the Judiciary'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([16., 13., 19.,  1.]),\n",
       "  'number': '81',\n",
       "  'title': 'The Judiciary Continued, and the Distribution of Judicial Authority'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([0., 4., 0., 0.]),\n",
       "  'number': '82',\n",
       "  'title': 'The Judiciary Continued'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([18., 20., 22.,  0.]),\n",
       "  'number': '83',\n",
       "  'title': 'The Judiciary Continued in Relation to Trial by Jury'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([20., 13., 16.,  0.]),\n",
       "  'number': '84',\n",
       "  'title': 'Certain General and Miscellaneous Objections to the Constitution Considered and Answered'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': tensor([18., 12., 10.,  0.]),\n",
       "  'number': '85',\n",
       "  'title': 'Concluding Remarks'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the papers by either of Madison and Hamilton\n",
    "training = list(filter(lambda ex: ex['authors'] in ['Madison', 'Hamilton'],\n",
    "                       dataset))\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers in the dataset: 66\n",
      "Some examples:\n",
      "[{'authors': 'Hamilton',\n",
      "  'counts': tensor([9., 6., 2., 0.]),\n",
      "  'number': '1',\n",
      "  'title': 'General Introduction'},\n",
      " {'authors': 'Hamilton',\n",
      "  'counts': tensor([2., 4., 7., 0.]),\n",
      "  'number': '6',\n",
      "  'title': 'Concerning Dangers from Dissensions Between the States'},\n",
      " {'authors': 'Hamilton',\n",
      "  'counts': tensor([13., 11.,  9.,  0.]),\n",
      "  'number': '7',\n",
      "  'title': 'The Same Subject Continued: Concerning Dangers from Dissensions '\n",
      "           'Between the States'}]\n"
     ]
    }
   ],
   "source": [
    "# View a sample of the training data\n",
    "print(f\"Number of papers in the dataset: {len(training)}\")\n",
    "print(\"Some examples:\")\n",
    "pprint(training[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Others of the papers are of ambiguous authorship. They are shown as having `'Hamilton or Madison'` as author. These will be the elements that we want to test our models on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'authors': 'Hamilton or Madison',\n",
       "  'counts': tensor([16.,  0.,  2.,  1.]),\n",
       "  'number': '49',\n",
       "  'title': 'Method of Guarding Against the Encroachments of Any One Department of Government by Appealing to the People Through a Convention'},\n",
       " {'authors': 'Hamilton or Madison',\n",
       "  'counts': tensor([11.,  1.,  0.,  0.]),\n",
       "  'number': '50',\n",
       "  'title': 'Periodic Appeals to the People Considered'},\n",
       " {'authors': 'Hamilton or Madison',\n",
       "  'counts': tensor([21.,  0.,  2.,  2.]),\n",
       "  'number': '51',\n",
       "  'title': 'The Structure of the Government Must Furnish the Proper Checks and Balances Between the Different Departments'},\n",
       " {'authors': 'Hamilton or Madison',\n",
       "  'counts': tensor([19.,  0.,  0.,  0.]),\n",
       "  'number': '52',\n",
       "  'title': 'The House of Representatives'},\n",
       " {'authors': 'Hamilton or Madison',\n",
       "  'counts': tensor([8., 0., 2., 1.]),\n",
       "  'number': '53',\n",
       "  'title': 'The Same Subject Continued: The House of Representatives'},\n",
       " {'authors': 'Hamilton or Madison',\n",
       "  'counts': tensor([19.,  1.,  1.,  0.]),\n",
       "  'number': '54',\n",
       "  'title': 'The Apportionment of Members Among States'},\n",
       " {'authors': 'Hamilton or Madison',\n",
       "  'counts': tensor([8., 0., 5., 0.]),\n",
       "  'number': '55',\n",
       "  'title': 'The Total Number of the House of Representatives'},\n",
       " {'authors': 'Hamilton or Madison',\n",
       "  'counts': tensor([11.,  0.,  3.,  1.]),\n",
       "  'number': '56',\n",
       "  'title': 'The Same Subject Continued: The Total Number of the House of Representatives'},\n",
       " {'authors': 'Hamilton or Madison',\n",
       "  'counts': tensor([19.,  0.,  4.,  3.]),\n",
       "  'number': '57',\n",
       "  'title': 'The Alleged Tendency of the Plan to Elevate the Few at the Expense of the Many Considered in Connection with Representation'},\n",
       " {'authors': 'Hamilton or Madison',\n",
       "  'counts': tensor([19.,  0.,  0.,  0.]),\n",
       "  'number': '62',\n",
       "  'title': 'The Senate'},\n",
       " {'authors': 'Hamilton or Madison',\n",
       "  'counts': tensor([20.,  0.,  8.,  1.]),\n",
       "  'number': '63',\n",
       "  'title': 'The Senate Continued'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the papers of unknown authorship\n",
    "testing = list(filter(lambda ex: ex['authors'] == 'Hamilton or Madison',\n",
    "                      dataset))\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers in the dataset: 11\n",
      "Some sample elements:\n",
      "[{'authors': 'Hamilton or Madison',\n",
      "  'counts': tensor([16.,  0.,  2.,  1.]),\n",
      "  'number': '49',\n",
      "  'title': 'Method of Guarding Against the Encroachments of Any One Department '\n",
      "           'of Government by Appealing to the People Through a Convention'},\n",
      " {'authors': 'Hamilton or Madison',\n",
      "  'counts': tensor([11.,  1.,  0.,  0.]),\n",
      "  'number': '50',\n",
      "  'title': 'Periodic Appeals to the People Considered'},\n",
      " {'authors': 'Hamilton or Madison',\n",
      "  'counts': tensor([21.,  0.,  2.,  2.]),\n",
      "  'number': '51',\n",
      "  'title': 'The Structure of the Government Must Furnish the Proper Checks and '\n",
      "           'Balances Between the Different Departments'}]\n"
     ]
    }
   ],
   "source": [
    "# View a sample of the data\n",
    "print(f\"Number of papers in the dataset: {len(testing)}\")\n",
    "print(\"Some sample elements:\")\n",
    "pprint(testing[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models for text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can think of a _model_ for a text classification problem as a function taking a test example and returning a class label for the test example. Generating the model will rely on a corpus of training data.\n",
    "\n",
    "With a model in hand, we can evaluate its _accuracy_ on a test corpus by computing the proportion of test examples that the model correctly classifies, that is, the model assigns to a test example the author that the test example specifies. Define a higher-order function `accuracy` that takes a test corpus (like `testing`) and a model (which is a function, remember), and returns the accuracy of the model on that corpus. \n",
    "\n",
    "> For you CS51 aficionados, `accuracy` is a _higher-order function_ since it _takes a function as an argument_. Yes, [higher-order functions are possible in Python](https://en.wikipedia.org/wiki/Higher-order_function#Python).\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: accuracy\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO -- Define the `accuracy` function.\n",
    "def accuracy(test_corpus, model):\n",
    "    \"\"\"Computes the accuracy of a model on a corpus.\n",
    "    Arguments:\n",
    "      `test_corpus`: a list of test examples, such as `testing`\n",
    "      `model`: a function whose input is an example from the corpus (such as \n",
    "              `testing[0]`, and whose output is the predicted author\n",
    "    Returns:\n",
    "      accuracy, a float number.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for example in test_corpus:\n",
    "        if(model(example) == example['authors']):\n",
    "            correct += 1\n",
    "    return correct/len(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Majority class classification\n",
    "\n",
    "An especially simple classification model labels each test example with whichever label happens to occur most frequently in the training data. It completely ignores the test example that it classifies!\n",
    "\n",
    "By examination of the table provided above, what is the majority class label for the training dataset?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: maj_class_label\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO -- Set this variable to the majority class label for the training set.\n",
    "maj_class_label = 'Hamilton'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd58da9f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"maj_class_label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Rather than determining the majority class by inspection, it's better to have a function to compute it for us. Define a function `majority_class_label` that returns the majority class label for a training set.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: majority_class_label\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO -- Define the `majority_class_label` function.\n",
    "def majority_class_label(training):\n",
    "    \"\"\"Find the majority class label for a training set.\n",
    "    Arguments:\n",
    "      `training`: a list of training examples, such as `training`\n",
    "    Returns:\n",
    "      the majority class label, a string.\n",
    "    \"\"\"\n",
    "    cnt = collections.Counter(map(lambda ex: ex['authors'],\n",
    "                              training))\n",
    "    maxAuthor, maxCount = cnt.most_common(1)[0]\n",
    "    return maxAuthor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f9f369e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"majority_class_label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "What proportions of the *training* examples do you think would be classified correctly by the majority class model?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: maj_class_accuracy_guess\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO -- Define this variable to be what you think the \n",
    "#        accuracy of the majority class model would be\n",
    "#        on the training data.\n",
    "\n",
    "maj_class_accuracy_guess = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1fbb0e4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"maj_class_accuracy_guess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now define a function `majority_class` that takes a single argument (a test example) and returns the particular class label that is most frequent in the training data `training` (regardless of what the test example is).\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: majority_class\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - Define the `majority_class` model.\n",
    "def majority_class(example):\n",
    "    \"\"\"Defines a majority class model.\n",
    "    Arguments:\n",
    "      `example`: an example, such as `testing[0]`\n",
    "    Returns:\n",
    "      the majority class in the *training* set, a string.\n",
    "    \"\"\"\n",
    "    return majority_class_label(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ec8c86c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"majority_class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now we can see how well this majority class model works by trying it out on some examples. Use the `accuracy` function to determine the model's accuracy when applied to the task of labeling the _training_ data.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: accuracy_maj_class_train\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO -- Define `maj_class_on_train` to be the accuracy of the majority \n",
    "#        class model on the training data.\n",
    "accuracy_maj_class_train = accuracy(training, majority_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d786439",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"accuracy_maj_class_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the majority class model on training data: 0.773\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of the majority class model on training data: \"\n",
    "      f\"{accuracy_maj_class_train:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was your guess from above right? No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbor classification\n",
    "\n",
    "Recall that nearest neighbor classification classifies a test example with the label of the nearest training example. To calculate nearest neighbors, we need a distance metric between the representations of the documents. Below we've provided two such metrics, familiar from the previous lab, for Euclidean distance and cosine distance.\n",
    "\n",
    "> Note: In order to allow full use of `torch` operations, these functions assume that the vectors are provided as tensors of type `float`. (That's why we tensorified the `counts` data as we loaded the dataset at the top  of this notebook.) When you call them, you'll want to make sure of this. They also return singleton tensors, not floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(v1, v2):\n",
    "    \"\"\"Returns the Euclidean distance between two vectors\"\"\"\n",
    "    return torch.linalg.norm(v1 - v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_acos(x):\n",
    "    \"\"\"Returns the arc cosine of `x`. Unlike `math.acos`, it \n",
    "       does not raise an exception for values of `x` out of range, \n",
    "       but rather clips `x` at -1..1, thereby avoiding math domain\n",
    "       errors in the case of numerical errors.\"\"\"\n",
    "    return math.acos(math.copysign(min(1.0, abs(x)), x))\n",
    "        \n",
    "def cosine_distance(v1, v2):\n",
    "    \"\"\"Returns the cosine distance between two vectors\"\"\"\n",
    "    dot_product = (v1 * v2).sum()\n",
    "    v1_norm = (v1 * v1).sum().sqrt()\n",
    "    v2_norm = (v2 * v2).sum().sqrt()\n",
    "    return safe_acos(dot_product / (v1_norm * v2_norm)) / math.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of the use of these distance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on two different tensors\n",
      "Euclidean: 2.8284270763397217\n",
      "Cosine   : 0.05724914679911019\n",
      "\n",
      "Testing on two identical tensors\n",
      "Euclidean: 0.0\n",
      "Cosine   : 0.0\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1., 2.])\n",
    "t2 = torch.tensor([3., 4.])\n",
    "\n",
    "print(\"Testing on two different tensors\\n\"\n",
    "      f\"Euclidean: {euclidean_distance(t1, t2)}\\n\"\n",
    "      f\"Cosine   : {cosine_distance(t1, t2)}\\n\\n\"\n",
    "      \"Testing on two identical tensors\\n\"\n",
    "      f\"Euclidean: {euclidean_distance(t1, t1)}\\n\"\n",
    "      f\"Cosine   : {cosine_distance(t1, t1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Generating nearest neighbor models\n",
    "\n",
    "To specify a nearest neighbor model, we need both a training corpus (like `training`) and a distance metric (like `euclidean_distance` or `cosine_distance` defined just above). \n",
    "\n",
    "Define a function called `define_nearest_neighbor` that takes a training corpus and a distance metric and returns a model -- that is, a function that classifies a single test example. The model should return the class _label_ of that training example whose _counts vector_ is closest to that of the test example according to the metric.\n",
    "\n",
    "> Again, harkening to CS51, `define_nearest_neighbor` is a higher-order function since it _returns a function_. Yes, [higher-order functions are possible in Python](https://en.wikipedia.org/wiki/Higher-order_function#Python).\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: define_nearest_neighbor\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO -- Define this function that generates nearest neighbor models.\n",
    "def define_nearest_neighbor(corpus, metric):\n",
    "    \"\"\"Generates a nearest neighbor model from a training corpus and a\n",
    "    distance metric.\n",
    "    Arguments:\n",
    "      `corpus`: a training corpus, such as `training`\n",
    "      `metric`: a metric function which takes two tensors as input and \n",
    "                returns their distance, such as `euclidean_distance`\n",
    "    Returns:\n",
    "      a model, which is a function that takes in a test example (such as \n",
    "      `testing[0]`) and returns the author of the nearest example in the \n",
    "      training set, where distances are measured on the counts vector \n",
    "      using `metric`.\n",
    "    \"\"\"\n",
    "    #test = corpus[0]\n",
    "    def model(test):\n",
    "        minDistance = math.inf\n",
    "        for example in corpus:\n",
    "            if(metric(test['counts'], example['counts']) < minDistance):\n",
    "                minDistance = metric(test['counts'], example['counts'])\n",
    "                minAuthor = example['authors']\n",
    "        return minAuthor\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `define_nearest_neighbor` function to define two new models for nearest neighbor classification, one using Euclidean distance and one using cosine distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbor_euclidean_model = define_nearest_neighbor(training, euclidean_distance)\n",
    "\n",
    "nearest_neighbor_cosine_model = define_nearest_neighbor(training, cosine_distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the nearest neighbor models on the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "How accurate are these models when used to label the training data (as we did for the majority class model above)? Use the `accuracy` function above to calculate the accuracy of `nearest_neighbor_euclidean_model` in labeling the _training_ data (not the test data), and similarly for `nearest_neighbor_cosine_model`.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: accuracy_train\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - Define the variable to be the calculated accuracy.\n",
    "accuracy_nn_euclidean_train = accuracy(training, nearest_neighbor_euclidean_model)\n",
    "accuracy_nn_cosine_train = accuracy(training, nearest_neighbor_euclidean_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95cfe56e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"accuracy_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the nearest neighbor euclidean model tested on training data: 1.000\n",
      "Accuracy of the nearest neighbor cosine model tested on training data: 1.000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of the nearest neighbor euclidean model tested on training data: \"\n",
    "      f\"{accuracy_nn_euclidean_train:.3f}\")\n",
    "print(f\"Accuracy of the nearest neighbor cosine model tested on training data: \"\n",
    "      f\"{accuracy_nn_cosine_train:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** Does the performance of these classifiers on the training data seem to you to be representative of how good a classifier each is? Why or why not?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957dd53c",
   "metadata": {},
   "source": [
    "No, they both have accuracy of 1.0 since they are being used on the training data. There is no separation between what the classifier was trained on and tested on, which would lead to 100% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "#### Testing the nearest neighbor models on the testing data\n",
    "\n",
    "To get a better sense of how the nearest neighbor models perform, let's try them out on the testing data that we have. (Recall that the testing data in `testing` were the ambiguously-authored Federalist papers, where the `authors` field was `'Hamilton or Madison'`.)\n",
    "\n",
    "We start by looking in detail at the predictions generated by the two nearest neighbor models. Print out a table that lists, for each `testing` example, the paper number and the authors predicted under the nearest neighbor Euclidean model and the nearest neighbor cosine model. It might look something like\n",
    "```\n",
    "49 Madison  Madison \n",
    "50 Hamilton Madison \n",
    "51 Madison  Madison\n",
    "...\n",
    "```\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: print_table\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Madison Madison\n",
      "1 Hamilton Madison\n",
      "2 Madison Madison\n",
      "3 Madison Madison\n",
      "4 Madison Madison\n",
      "5 Madison Madison\n",
      "6 Madison Hamilton\n",
      "7 Madison Madison\n",
      "8 Madison Madison\n",
      "9 Madison Madison\n",
      "10 Madison Madison\n"
     ]
    }
   ],
   "source": [
    "#TODO - Print out the requested table.\n",
    "for i in range(len(testing)):\n",
    "    x = nearest_neighbor_euclidean_model(testing[i])\n",
    "    #print(x)\n",
    "    y = nearest_neighbor_cosine_model(testing[i])\n",
    "    #print(y)\n",
    "    print(str(i) +\" \"+ x +\" \"+ y)\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "What do you notice about the two models?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_2\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc8573",
   "metadata": {},
   "source": [
    "They seem to be returning the same values most of the time and mainly Madison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Testing the nearest neighbor models on the training data\n",
    "\n",
    "Now use the `accuracy` function to calculate the accuracy of the two nearest neighbor models as you did above, but this time calculating accuracy on the *testing* corpus rather than the training corpus. (Expect to find a surprising result. Read ahead for an explanation if you're confused.)\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: accuracy_test\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO -- Define the variables to be, respectively, the calculated accuracy of the nearest \n",
    "#        neighbor Euclidean model and cosine model on the testing data.\n",
    "accuracy_nn_euclidean_test = accuracy(testing, nearest_neighbor_euclidean_model)\n",
    "accuracy_nn_cosine_test = accuracy(testing, nearest_neighbor_cosine_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d787e83",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"accuracy_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the nearest neighbor euclidean model tested on testing data: 0.000\n",
      "Accuracy of the nearest neighbor cosine model tested on testing data: 0.000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of the nearest neighbor euclidean model tested on testing data: \"\n",
    "      f\"{accuracy_nn_euclidean_test:.3f}\")\n",
    "print(f\"Accuracy of the nearest neighbor cosine model tested on testing data: \"\n",
    "      f\"{accuracy_nn_cosine_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** Does the performance of these classifiers on the testing data seem to you to be representative of how good a classifier each is? Why or why not?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_3\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1254e76a",
   "metadata": {},
   "source": [
    "Yes, the performance of the classifiers in testing data are more representative of how good the classifier is because it allows for testing on a different dataset from what was trained on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### The importance of gold labels\n",
    "\n",
    "In order to evaluate the accuracy of the nearest neighbor model – and any model – we need to have the correct labels for the testing corpus, the so-called _gold_ labels. What shall we use for gold labels? Mosteller and Wallace's much more extensive analysis concluded that all of the papers of ambiguous origin were penned by Madison, so we'll use that. We should use a version of the `testing` corpus with the gold labels. \n",
    "\n",
    "Write some code to generate a version of the testing corpus with the gold labels.\n",
    "\n",
    "> Hint: In defining `testing_gold`, you'll want to be careful not to change `testing`. Otherwise, some unit tests that use `testing` may fail. The `copy.deepcopy` function may be useful.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: get_gold\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - Write code that defines `testing_gold`, which is the same\n",
    "# as `testing` except that it has the correct gold labels.\n",
    "# Note: be careful to not change `testing`.\n",
    "testing_gold = copy.deepcopy(testing)\n",
    "for ex in testing_gold:\n",
    "    ex['authors'] = 'Madison'\n",
    "#testing_gold[0]['authors'] = 'Madison'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf1514eb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"get_gold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can rerun the accuracy calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_nn_euclidean_test_with_gold = accuracy(testing_gold, nearest_neighbor_euclidean_model)\n",
    "accuracy_nn_cosine_test_with_gold = accuracy(testing_gold, nearest_neighbor_cosine_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the nearest neighbor euclidean model tested on testing data: 0.909\n",
      "Accuracy of the nearest neighbor cosine model tested on testing data: 0.909\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of the nearest neighbor euclidean model tested on testing data: \"\n",
    "      f\"{accuracy_nn_euclidean_test_with_gold:.3f}\")\n",
    "print(f\"Accuracy of the nearest neighbor cosine model tested on testing data: \"\n",
    "      f\"{accuracy_nn_cosine_test_with_gold:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do these results make more sense? Yes, they do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "# Lab debrief – for consensus submission only\n",
    "\n",
    "**Question:** We're interested in any thoughts your group has about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on include the following: \n",
    "\n",
    "* Was the lab too long or too short?\n",
    "* Were the readings appropriate for the lab? \n",
    "* Was it clear (at least after you completed the lab) what the points of the exercises were? \n",
    "* Are there additions or changes you think would make the lab better?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_debrief\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2af648",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# End of lab 1-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3afb02d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c03ac370",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong>accuracy_maj_class_train:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>accuracy_test:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>accuracy_train:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>get_gold:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>maj_class_accuracy_guess:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>maj_class_label:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>majority_class:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>majority_class_label:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n"
      ],
      "text/plain": [
       "accuracy_maj_class_train:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "accuracy_test:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "accuracy_train:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "get_gold:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "maj_class_accuracy_guess:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "maj_class_label:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "majority_class:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "majority_class_label:\n",
       "\n",
       "    All tests passed!\n",
       "    \n"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "title": "CS187 Lab 1-2: Text classification and evaluation methodology"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
