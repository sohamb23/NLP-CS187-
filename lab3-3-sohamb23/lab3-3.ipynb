{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c700d39",
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Please do not change this cell because some hidden tests might depend on it.\n",
    "import os\n",
    "\n",
    "# Otter grader does not handle ! commands well, so we define and use our\n",
    "# own function to execute shell commands.\n",
    "def shell(commands, warn=True):\n",
    "    \"\"\"Executes the string `commands` as a sequence of shell commands.\n",
    "     \n",
    "       Prints the result to stdout and returns the exit status. \n",
    "       Provides a printed warning on non-zero exit status unless `warn` \n",
    "       flag is unset.\n",
    "    \"\"\"\n",
    "    file = os.popen(commands)\n",
    "    print (file.read().rstrip('\\n'))\n",
    "    exit_status = file.close()\n",
    "    if warn and exit_status != None:\n",
    "        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n",
    "    return exit_status\n",
    "\n",
    "shell(\"\"\"\n",
    "ls requirements.txt >/dev/null 2>&1\n",
    "if [ ! $? = 0 ]; then\n",
    " rm -rf .tmp\n",
    " git clone https://github.com/cs187-2021/lab3-3.git .tmp\n",
    " mv .tmp/tests ./\n",
    " mv .tmp/requirements.txt ./\n",
    " rm -rf .tmp\n",
    "fi\n",
    "pip install -q -r requirements.txt\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee7ae6d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d70dce24",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "%%latex\n",
    "\\newcommand{\\vect}[1]{\\mathbf{#1}}\n",
    "\\newcommand{\\cnt}[1]{\\sharp(#1)}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\softmax}{\\operatorname{softmax}}\n",
    "\\newcommand{\\Prob}{\\Pr}\n",
    "\\newcommand{\\given}{\\,|\\,}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4698fb4d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "$$\n",
    "\\renewcommand{\\vect}[1]{\\mathbf{#1}}\n",
    "\\renewcommand{\\cnt}[1]{\\sharp(#1)}\n",
    "\\renewcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\renewcommand{\\softmax}{\\operatorname{softmax}}\n",
    "\\renewcommand{\\Prob}{\\Pr}\n",
    "\\renewcommand{\\given}{\\,|\\,}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637d6783",
   "metadata": {
    "colab_type": "text",
    "id": "YhNwlK5J_wU_",
    "tags": [
     "remove_for_latex"
    ]
   },
   "source": [
    "# CS187\n",
    "## Lab 3-3 - Probabilistic context-free grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4adb15",
   "metadata": {
    "colab_type": "text",
    "id": "w9cQ2kCv_zax"
   },
   "source": [
    "In previous labs, you have practiced constituency parsing using context-free grammars with the CKY parsing algorithm. In this lab you will extend this framework to a probabilistic one, probabilistic context-free grammars (PCFG)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a112a6d6",
   "metadata": {},
   "source": [
    "New bits of Python used for the first time in the _solution set_ for this lab, and which you may therefore find useful:\n",
    "\n",
    "* [`math.prod`](https://docs.python.org/3/library/math.html#math.prod)\n",
    "* [`nltk.tree.Tree.productions`](https://www.nltk.org/api/nltk.html?highlight=production#nltk.tree.Tree.productions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d81f768",
   "metadata": {},
   "source": [
    "# Preparations {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab7b9545",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "d8kPmrmwB2U9"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import nltk\n",
    "import operator\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8a97de",
   "metadata": {
    "colab_type": "text",
    "id": "ieywAjIBFLbz"
   },
   "source": [
    "# Syntactic ambiguity\n",
    "\n",
    "Let's start with the following simplified grammar for arithmetic word expressions from the last lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79cbb726",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8kPmrmwB2U9"
   },
   "outputs": [],
   "source": [
    "arithmetic_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NUM | S OP S\n",
    "    OP -> ADD | MULT\n",
    "\n",
    "    NUM -> 'zero' | 'one' | 'two' | 'three' | 'four' | 'five'\n",
    "    NUM -> 'six' | 'seven' | 'eight' | 'nine' | 'ten' \n",
    "    \n",
    "    ADD -> 'plus'\n",
    "    MULT -> 'times'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76673a64",
   "metadata": {},
   "source": [
    "As a running example throughout this lab, we'll use the example phrase \"two times three plus four\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b71df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"two plus three times four\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e909f8",
   "metadata": {
    "colab_type": "text",
    "id": "JIt2BY8yGIqP"
   },
   "source": [
    "We can use the given CFG to parse this example phrase and print the possible parse trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb85d85",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SMI2sSeQLnv-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse 1:\n",
      "\n",
      "           S             \n",
      "      _____|__________    \n",
      "     S           |    |  \n",
      "  ___|_____      |    |   \n",
      " S   OP    S     OP   S  \n",
      " |   |     |     |    |   \n",
      "NUM ADD   NUM   MULT NUM \n",
      " |   |     |     |    |   \n",
      "two plus three times four\n",
      "\n",
      "Parse 2:\n",
      "\n",
      "           S             \n",
      "  _________|_____         \n",
      " |   |           S       \n",
      " |   |      _____|____    \n",
      " S   OP    S     OP   S  \n",
      " |   |     |     |    |   \n",
      "NUM ADD   NUM   MULT NUM \n",
      " |   |     |     |    |   \n",
      "two plus three times four\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.parse.BottomUpChartParser(arithmetic_grammar)\n",
    "parses = list(parser.parse(example.split()))\n",
    "\n",
    "for i, tree in enumerate(parses):\n",
    "  print(f\"Parse {i+1}:\\n\")\n",
    "  tree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33654f11",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "v0vIENitPzq9"
   },
   "source": [
    "Each parse tree represents a structured arithmetic expression (the _abstract syntax_ of the concrete expression,  for those of you with CS51 backgrounds). Manually calculate the value of the resulting equation for each of the parse trees.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: parsed_equation_result\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fe04f5f",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iEzvvFvDP77I"
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "result_tree1 = 20\n",
    "result_tree2 = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3623457",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"parsed_equation_result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd3128b",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "Eqsvobh2Rx4Y"
   },
   "source": [
    "We got two different parse trees for this simple expression. The occurrence of different structural interpretations of the same text is called _structural ambiguity_ or _syntactic ambiguity_. Since natural language is oftentimes ambiguous, this is a very real concern.\n",
    "\n",
    "In this particular case, the two syntactic structures corresponded to two different semantic values. As an exercise, try to construct an ambiguous expression (name it `pseudo_ambiguous`) such that all of its parse trees correspond to the same value, thereby demonstrating that not all structural ambiguity leads to semantic ambiguity.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: redundant_parses\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71e3bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - construct an ambiguous expression such that all of its parse\n",
    "# trees correspond to the same value. `pseudo_ambiguous` should be\n",
    "# a string.\n",
    "pseudo_ambiguous = \"one plus one times one\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7a0880d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"redundant_parses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453fd33",
   "metadata": {
    "colab_type": "text",
    "id": "Eqsvobh2Rx4Y"
   },
   "source": [
    "One approach to dealing with the issue of syntactic ambiguity is by defining a scoring system to score the possible parses and choosing the highest scoring tree. We will see how this can be done by taking a probabilistic approach to CFG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ea9b8",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "UgobxGF0WZ7V"
   },
   "source": [
    "# Probabilistic context-free grammars\n",
    "\n",
    "To assign probabilities to strings, we will use a probabilistic context-free grammar (PCFG), a CFG in which each rule is augmented with a probability. A PCFG rule will be notated\n",
    "$$A \\to \\beta\\ [p]$$\n",
    "where $A$ is a nonterminal, $\\beta$ is a sequence of terminals and nonterminals, and $p$ is a probability associated with the rule.\n",
    "\n",
    "We'll write $\\Prob(\\beta \\given A)$ for the probability associated with the rule $A \\to \\beta$.\n",
    "\n",
    "To constitute a valid probability distribution we require that for every nonterminal $A$\n",
    "$$\\sum_{A \\to \\beta \\in \\cal{P}} \\Prob(\\beta \\given A) = 1$$\n",
    "where $\\cal{P}$ is the set of CFG productions of the grammar. That is, the probabilities associated with all rules with the same left-hand side must sum to one.\n",
    "\n",
    "Define `probabilistic_arithmetic_grammar` to be a proabilistic version of `arithmetic grammar` above, where the nonterminal probability distributions are **as uniform across the productions as possible**.\n",
    "\n",
    "> You'll use the NLTK `nltk.PCFG.fromstring` function, which allows you to add the probabilities in brackets after each right=hand side, just as we've been doing above. For example, to notate `NUM -> 'zero'` as of probability 0.5, use `NUM -> 'zero' [0.5]`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: uniform_probabilities\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e936ccf0",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MMKDQ9sXNRs"
   },
   "outputs": [],
   "source": [
    "# TODO - define `probabilistic_arithmetic_grammar`. Round to\n",
    "#        *3* significant figures if not divisible.\n",
    "\n",
    "probabilistic_arithmetic_grammar = nltk.PCFG.fromstring(\"\"\"\n",
    "    S -> NUM [0.5]| S OP S [0.5]\n",
    "    OP -> ADD [0.5]| MULT [0.5]\n",
    "\n",
    "    NUM -> 'zero' [0.0909] | 'one' [0.0909]| 'two' [0.0909]| 'three' [0.0909]| 'four' [0.0909]| 'five' [0.0909]\n",
    "    NUM -> 'six' [0.0909]| 'seven' [0.0909]| 'eight' [0.0909]| 'nine' [0.0909]| 'ten' [0.0909]\n",
    "    \n",
    "    ADD -> 'plus' [1]\n",
    "    MULT -> 'times' [1]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23368627",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"uniform_probabilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c6e98e",
   "metadata": {
    "colab_type": "text",
    "id": "LJ155LVeUU9y"
   },
   "source": [
    "We can use the [nltk.CFG.productions()](https://www.nltk.org/api/nltk.html?highlight=production#nltk.grammar.CFG.productions) method to get a list of the PCFG's productions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b16e462d",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5pBrhCvNUs9m"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S -> NUM [0.5],\n",
       " S -> S OP S [0.5],\n",
       " OP -> ADD [0.5],\n",
       " OP -> MULT [0.5],\n",
       " NUM -> 'zero' [0.0909],\n",
       " NUM -> 'one' [0.0909],\n",
       " NUM -> 'two' [0.0909],\n",
       " NUM -> 'three' [0.0909],\n",
       " NUM -> 'four' [0.0909],\n",
       " NUM -> 'five' [0.0909],\n",
       " NUM -> 'six' [0.0909],\n",
       " NUM -> 'seven' [0.0909],\n",
       " NUM -> 'eight' [0.0909],\n",
       " NUM -> 'nine' [0.0909],\n",
       " NUM -> 'ten' [0.0909],\n",
       " ADD -> 'plus' [1.0],\n",
       " MULT -> 'times' [1.0]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilistic_arithmetic_grammar.productions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7316abc",
   "metadata": {
    "colab_type": "text",
    "id": "Mq8J8fQxVF4Y"
   },
   "source": [
    "Each of the productions in the list is an instance of the [ProbabilisticProduction](https://www.nltk.org/api/nltk.html?highlight=production#nltk.grammar.ProbabilisticProduction) class. Each such instance is defined by three parameters: its left hand side (`lhs`), right-hand side (`rhs`), and rule probability (`prob`). These attributes can be accessed separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "181fb6f4",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4TZUYEE3Vyxt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the production \"S -> S OP S [0.5]\":\n",
      "left hand side of the rule is S\n",
      "right hand side of the rule is (S, OP, S)\n",
      "probability of the rule is 0.5\n"
     ]
    }
   ],
   "source": [
    "## Extract the second rule\n",
    "pprod_example = probabilistic_arithmetic_grammar.productions()[1]\n",
    "\n",
    "## Display its various components\n",
    "print(f'For the production \"{pprod_example}\":\\n' \n",
    "      f'left hand side of the rule is {pprod_example.lhs()}\\n'\n",
    "      f'right hand side of the rule is {pprod_example.rhs()}\\n'\n",
    "      f'probability of the rule is {pprod_example.prob()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0007f3",
   "metadata": {
    "colab_type": "text",
    "id": "Qx8sTaCVWIcg"
   },
   "source": [
    "For non-probabilistic grammars, the class of productions is [Production](https://www.nltk.org/api/nltk.html?highlight=production#nltk.grammar.Production), which doesn't have a probability attribute and is only defined by its lhs and rhs attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28f0fc74",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s67fRZjFXK4u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCFG production: S -> S OP S [0.5] \n",
      "      vs.\n",
      "CFG production:  S -> S OP S\n"
     ]
    }
   ],
   "source": [
    "print(f'PCFG production: {probabilistic_arithmetic_grammar.productions()[1]} \\n'\n",
    "      f'      vs.\\n'\n",
    "      f'CFG production:  {arithmetic_grammar.productions()[1]}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dda3be",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "NTRVDqDjF18j"
   },
   "source": [
    "# Parse tree probabilities\n",
    "\n",
    "To use a PCFG to select among parse trees, we need to be able to calculate the probability of a parse tree as specified by the PCFG. We take the probability of a parse tree to be simply the product of the probabilities of each constituent in the tree, the probability of the rule associated with the constituent.\n",
    "\n",
    "You'll use the PCFG `probabilistic_arithmetic_grammar` to calculate the probability of each of the parse trees in `parses`, the list of trees that were parsed from the `example` sentence. \n",
    "\n",
    "To do that, you'll need to get all the productions used in a parse tree (using the [productions](https://www.nltk.org/api/nltk.html?highlight=production#nltk.tree.Tree.productions) method), find their probabilities, and multiply them together.\n",
    "\n",
    "First, we will create a dictionary from the PCFG, so that we can easily access the rule probabilities. Write a function which accepts a PCFG and returns a dictionary whose keys are the CFG (not PCFG) productions and values are the associated probabilities. \n",
    "\n",
    "> To construct a CFG production from a PCFG production, you can use `nltk.grammar.Production(production.lhs(), production.rhs())`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: pcfg_to_dict\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0045d7fd",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wzrUO1KNuUz4"
   },
   "outputs": [],
   "source": [
    "#TODO - returns a dictionary whose keys are `nltk.grammar.Production` objects\n",
    "#       and whose values are the associated probabilities\n",
    "def pcfg_to_dict(pcfg):\n",
    "    pcfgDict = {}\n",
    "    #production = probabilistic_arithmetic_grammar.productions()\n",
    "    #cfgProduction = nltk.grammar.Production(production.lhs(), production.rhs())\n",
    "    for example in pcfg.productions():\n",
    "        pcfgDict[nltk.grammar.Production(example.lhs(), example.rhs())] = example.prob()\n",
    "    return pcfgDict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82192819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S -> NUM [0.5], S -> S OP S [0.5], OP -> ADD [0.5], OP -> MULT [0.5], NUM -> 'zero' [0.0909], NUM -> 'one' [0.0909], NUM -> 'two' [0.0909], NUM -> 'three' [0.0909], NUM -> 'four' [0.0909], NUM -> 'five' [0.0909], NUM -> 'six' [0.0909], NUM -> 'seven' [0.0909], NUM -> 'eight' [0.0909], NUM -> 'nine' [0.0909], NUM -> 'ten' [0.0909], ADD -> 'plus' [1.0], MULT -> 'times' [1.0]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lhs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/09/v1n7m90x4x19d0b5zn46swr80000gn/T/ipykernel_17441/3214698299.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mproduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobabilistic_arithmetic_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproductions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcfgProduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfgProduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lhs'"
     ]
    }
   ],
   "source": [
    "production = probabilistic_arithmetic_grammar.productions()\n",
    "print(production)\n",
    "cfgProduction = nltk.grammar.Production(production.lhs(), production.rhs())\n",
    "print(cfgProduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0f451bf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"pcfg_to_dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bf11b3",
   "metadata": {
    "colab_type": "text",
    "id": "1ImGQNeTHwRT"
   },
   "source": [
    "We can use the function you wrote to convert `probabilistic_arithmetic_grammar` to a dictionary and inspect it to make sure it's working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7049a7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ADD -> 'plus': 1.0,\n",
      " MULT -> 'times': 1.0,\n",
      " NUM -> 'eight': 0.0909,\n",
      " NUM -> 'five': 0.0909,\n",
      " NUM -> 'four': 0.0909,\n",
      " NUM -> 'nine': 0.0909,\n",
      " NUM -> 'one': 0.0909,\n",
      " NUM -> 'seven': 0.0909,\n",
      " NUM -> 'six': 0.0909,\n",
      " NUM -> 'ten': 0.0909,\n",
      " NUM -> 'three': 0.0909,\n",
      " NUM -> 'two': 0.0909,\n",
      " NUM -> 'zero': 0.0909,\n",
      " OP -> ADD: 0.5,\n",
      " OP -> MULT: 0.5,\n",
      " S -> NUM: 0.5,\n",
      " S -> S OP S: 0.5}\n"
     ]
    }
   ],
   "source": [
    "pprint(pcfg_to_dict(probabilistic_arithmetic_grammar))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217fa22",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "1ImGQNeTHwRT"
   },
   "source": [
    "Now for the payoff: Write a function that takes a parse tree and a PCFG and returns the probability of the parse tree according to the PCFG. The `pcfg_to_dict` function you just wrote is likely to come in handy.\n",
    "\n",
    "> Note that we are asking for the probability (not the log probability). We **don't work in log space** in this lab for simplicity, but for parse trees of longer sentences (which you'll see in the project) you might have to work in the log space to avoid underflows.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: parsed_trees_probs\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "322bdc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: returns the probability of the parse tree.\n",
    "# `tree.productions() might be useful for getting the \n",
    "#  productions of a parse tree\n",
    "def parse_probability(tree, pcfg):\n",
    "    pcfgDict = pcfg_to_dict(pcfg)\n",
    "    prob = 1\n",
    "    for key in tree.productions():\n",
    "        prob *= pcfgDict[key]\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71411514",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"parsed_trees_probs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c4299e",
   "metadata": {
    "colab_type": "text",
    "id": "1ImGQNeTHwRT"
   },
   "source": [
    "We'll use it to calculate and print out the probability of each parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10a80843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of parse tree 1 is 5.87e-06\n",
      "           S             \n",
      "      _____|__________    \n",
      "     S           |    |  \n",
      "  ___|_____      |    |   \n",
      " S   OP    S     OP   S  \n",
      " |   |     |     |    |   \n",
      "NUM ADD   NUM   MULT NUM \n",
      " |   |     |     |    |   \n",
      "two plus three times four\n",
      "\n",
      "Probability of parse tree 2 is 5.87e-06\n",
      "           S             \n",
      "  _________|_____         \n",
      " |   |           S       \n",
      " |   |      _____|____    \n",
      " S   OP    S     OP   S  \n",
      " |   |     |     |    |   \n",
      "NUM ADD   NUM   MULT NUM \n",
      " |   |     |     |    |   \n",
      "two plus three times four\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, tree in enumerate(parses):\n",
    "    print(f'Probability of parse tree {i+1} is '\n",
    "          f'{parse_probability(tree, probabilistic_arithmetic_grammar):1.2e}')\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6a0ae0",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "h2F-sJGitFgs"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** Which of the trees is the most probable parse? Explain why. If the two have the same probability, explain why that is the case instead, and describe how you might adjust the rule probabilities if possible so that they have different probabilities.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_ambiguity\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b58da5",
   "metadata": {},
   "source": [
    "The two trees have the same probability because they are constructed out of the same set of productions. Since the productions are the same across both the trees, the multiplied probability is also the same across both of the trees. One way that the rule probabilities could be adjusted is changing the probability for "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c3014",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# Lexicalizing the grammar\n",
    "\n",
    "In order to allow parse probabilities to be more sensitive to contexts, it turns out to be useful to _lexicalize_ the grammar -- splitting (some of the) nonterminals based on what particular words they dominate. There are many techniques for performing this lexicalization. For this grammar, we'll split the `S` nonterminal based on the main operator that it dominates (if any). We'll thus have nonterminals `S_ADD`, `S_MULT`, and `S_NUM`. Thus, instead of a rule `S -> S OP S`, we'll have rules like:\n",
    "\n",
    "```\n",
    "S_ADD -> S_NUM ADD S_NUM\n",
    "S_ADD -> S_NUM ADD S_ADD\n",
    "S_ADD -> S_NUM ADD S_MULT\n",
    "S_ADD -> S_ADD ADD S_NUM\n",
    "``` \n",
    "and so forth. By splitting the nonterminals (and hence the productions) in this way, we can assign different probabilities to cases where, for instance, the primary operator on the left is a number, or addition, or multiplication.\n",
    "\n",
    "Here is the lexicalized grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e52c9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicalized_arithmetic_grammar = nltk.CFG.fromstring( \n",
    "    \"\"\"\n",
    "    S -> S_NUM | S_ADD | S_MULT\n",
    "\n",
    "    S_NUM -> NUM\n",
    "\n",
    "    S_ADD -> S_NUM ADD S_NUM\n",
    "    S_ADD -> S_NUM ADD S_ADD\n",
    "    S_ADD -> S_NUM ADD S_MULT\n",
    "    S_ADD -> S_ADD ADD S_NUM\n",
    "    S_ADD -> S_ADD ADD S_ADD\n",
    "    S_ADD -> S_ADD ADD S_MULT\n",
    "    S_ADD -> S_MULT ADD S_NUM\n",
    "    S_ADD -> S_MULT ADD S_ADD\n",
    "    S_ADD -> S_MULT ADD S_MULT\n",
    "\n",
    "    S_MULT -> S_NUM MULT S_NUM\n",
    "    S_MULT -> S_NUM MULT S_ADD\n",
    "    S_MULT -> S_NUM MULT S_MULT\n",
    "    S_MULT -> S_ADD MULT S_NUM\n",
    "    S_MULT -> S_ADD MULT S_ADD\n",
    "    S_MULT -> S_ADD MULT S_MULT\n",
    "    S_MULT -> S_MULT MULT S_NUM\n",
    "    S_MULT -> S_MULT MULT S_ADD\n",
    "    S_MULT -> S_MULT MULT S_MULT\n",
    "\n",
    "    NUM -> 'zero'   | 'one'    | 'two'\n",
    "    NUM -> 'three'  | 'four'   | 'five'\n",
    "    NUM -> 'six'    | 'seven'  | 'eight'\n",
    "    NUM -> 'nine'   | 'ten'\n",
    "\n",
    "    ADD -> 'plus'\n",
    "    MULT -> 'times'\n",
    "    \"\"\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1261bb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Use this grammar to parse the example phrase (\"two plus three times four\") defined as `phrase` above.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: lexicalized_parse\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21ef874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - parse `example` using the lexicalized grammar. `lexicalized_parses`\n",
    "#        should be a list of parses.\n",
    "parser = nltk.parse.BottomUpChartParser(lexicalized_arithmetic_grammar)\n",
    "lexicalized_parses = list(parser.parse(example.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ba84a07",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"lexicalized_parse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d38d2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "Examine the trees, and make sure that you understand why they look the way they do. Notice that because of the lexicalization, the highest `S_` node corresponds to the highest operator in the parse -- `S_MULT` when `MULT` is the highest operator and `S_ADD` when `ADD` is the highest operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ff0787f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible parse 1:\n",
      "\n",
      "              S               \n",
      "              |                \n",
      "            S_MULT            \n",
      "         _____|____________    \n",
      "      S_ADD          |     |  \n",
      "   _____|_____       |     |   \n",
      "S_NUM   |   S_NUM    |   S_NUM\n",
      "  |     |     |      |     |   \n",
      " NUM   ADD   NUM    MULT  NUM \n",
      "  |     |     |      |     |   \n",
      " two   plus three  times  four\n",
      "\n",
      "Possible parse 2:\n",
      "\n",
      "             S               \n",
      "             |                \n",
      "           S_ADD             \n",
      "   __________|_____           \n",
      "  |    |         S_MULT      \n",
      "  |    |      _____|______    \n",
      "S_NUM  |   S_NUM   |    S_NUM\n",
      "  |    |     |     |      |   \n",
      " NUM  ADD   NUM   MULT   NUM \n",
      "  |    |     |     |      |   \n",
      " two  plus three times   four\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, tree in enumerate(lexicalized_parses):\n",
    "  print(f\"Possible parse {i+1}:\\n\")\n",
    "  tree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3bfa08",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can augment this grammar with probabilities as well.\n",
    "\n",
    "Again, do so making the probabilities as uniform as possible.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: uniform_lexicalized_probabilities\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7e04c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - define `probabilistic_lexicalized_arithmetic_grammar`.\n",
    "#        Round to *3* significant figures if not divisible.\n",
    "probabilistic_lexicalized_arithmetic_grammar = nltk.PCFG.fromstring( \n",
    "    \"\"\"\n",
    "    S -> S_NUM [0.333]| S_ADD [0.333]| S_MULT [0.333]\n",
    "\n",
    "    S_NUM -> NUM [1]\n",
    "\n",
    "    S_ADD -> S_NUM ADD S_NUM [0.111]\n",
    "    S_ADD -> S_NUM ADD S_ADD [0.111]\n",
    "    S_ADD -> S_NUM ADD S_MULT [0.111]\n",
    "    S_ADD -> S_ADD ADD S_NUM [0.111]\n",
    "    S_ADD -> S_ADD ADD S_ADD [0.111]\n",
    "    S_ADD -> S_ADD ADD S_MULT [0.111]\n",
    "    S_ADD -> S_MULT ADD S_NUM [0.111]\n",
    "    S_ADD -> S_MULT ADD S_ADD [0.111]\n",
    "    S_ADD -> S_MULT ADD S_MULT [0.111]\n",
    "\n",
    "    S_MULT -> S_NUM MULT S_NUM [0.111]\n",
    "    S_MULT -> S_NUM MULT S_ADD [0.111]\n",
    "    S_MULT -> S_NUM MULT S_MULT [0.111]\n",
    "    S_MULT -> S_ADD MULT S_NUM [0.111]\n",
    "    S_MULT -> S_ADD MULT S_ADD [0.111]\n",
    "    S_MULT -> S_ADD MULT S_MULT [0.111]\n",
    "    S_MULT -> S_MULT MULT S_NUM [0.111]\n",
    "    S_MULT -> S_MULT MULT S_ADD [0.111]\n",
    "    S_MULT -> S_MULT MULT S_MULT [0.111]\n",
    "\n",
    "    NUM -> 'zero' [0.0909]  | 'one' [0.0909]   | 'two' [0.0909]\n",
    "    NUM -> 'three' [0.0909] | 'four' [0.0909]  | 'five' [0.0909]\n",
    "    NUM -> 'six'  [0.0909]  | 'seven' [0.0909] | 'eight' [0.0909]\n",
    "    NUM -> 'nine' [0.0909]  | 'ten' [0.0909]\n",
    "\n",
    "    ADD -> 'plus' [1]\n",
    "    MULT -> 'times' [1]\n",
    "    \"\"\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be703b4e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"uniform_lexicalized_probabilities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eaa79ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{S -> S_NUM: 0.333,\n",
       " S -> S_ADD: 0.333,\n",
       " S -> S_MULT: 0.333,\n",
       " S_NUM -> NUM: 1.0,\n",
       " S_ADD -> S_NUM ADD S_NUM: 0.111,\n",
       " S_ADD -> S_NUM ADD S_ADD: 0.111,\n",
       " S_ADD -> S_NUM ADD S_MULT: 0.111,\n",
       " S_ADD -> S_ADD ADD S_NUM: 0.111,\n",
       " S_ADD -> S_ADD ADD S_ADD: 0.111,\n",
       " S_ADD -> S_ADD ADD S_MULT: 0.111,\n",
       " S_ADD -> S_MULT ADD S_NUM: 0.111,\n",
       " S_ADD -> S_MULT ADD S_ADD: 0.111,\n",
       " S_ADD -> S_MULT ADD S_MULT: 0.111,\n",
       " S_MULT -> S_NUM MULT S_NUM: 0.111,\n",
       " S_MULT -> S_NUM MULT S_ADD: 0.111,\n",
       " S_MULT -> S_NUM MULT S_MULT: 0.111,\n",
       " S_MULT -> S_ADD MULT S_NUM: 0.111,\n",
       " S_MULT -> S_ADD MULT S_ADD: 0.111,\n",
       " S_MULT -> S_ADD MULT S_MULT: 0.111,\n",
       " S_MULT -> S_MULT MULT S_NUM: 0.111,\n",
       " S_MULT -> S_MULT MULT S_ADD: 0.111,\n",
       " S_MULT -> S_MULT MULT S_MULT: 0.111,\n",
       " NUM -> 'zero': 0.0909,\n",
       " NUM -> 'one': 0.0909,\n",
       " NUM -> 'two': 0.0909,\n",
       " NUM -> 'three': 0.0909,\n",
       " NUM -> 'four': 0.0909,\n",
       " NUM -> 'five': 0.0909,\n",
       " NUM -> 'six': 0.0909,\n",
       " NUM -> 'seven': 0.0909,\n",
       " NUM -> 'eight': 0.0909,\n",
       " NUM -> 'nine': 0.0909,\n",
       " NUM -> 'ten': 0.0909,\n",
       " ADD -> 'plus': 1.0,\n",
       " MULT -> 'times': 1.0}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcfg_to_dict(probabilistic_lexicalized_arithmetic_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a455b8",
   "metadata": {},
   "source": [
    "Using this PCFG, we can calculate the probabilities associated with the two parses of the example phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa7c1d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of parsed tree 1 is 3.08e-06\n",
      "              S               \n",
      "              |                \n",
      "            S_MULT            \n",
      "         _____|____________    \n",
      "      S_ADD          |     |  \n",
      "   _____|_____       |     |   \n",
      "S_NUM   |   S_NUM    |   S_NUM\n",
      "  |     |     |      |     |   \n",
      " NUM   ADD   NUM    MULT  NUM \n",
      "  |     |     |      |     |   \n",
      " two   plus three  times  four\n",
      "\n",
      "Probability of parsed tree 2 is 3.08e-06\n",
      "             S               \n",
      "             |                \n",
      "           S_ADD             \n",
      "   __________|_____           \n",
      "  |    |         S_MULT      \n",
      "  |    |      _____|______    \n",
      "S_NUM  |   S_NUM   |    S_NUM\n",
      "  |    |     |     |      |   \n",
      " NUM  ADD   NUM   MULT   NUM \n",
      "  |    |     |     |      |   \n",
      " two  plus three times   four\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, tree in enumerate(lexicalized_parses):\n",
    "    print(f'Probability of parsed tree {i+1} is '\n",
    "          f'{parse_probability(tree, probabilistic_lexicalized_arithmetic_grammar):1.2e}')\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de48d1",
   "metadata": {},
   "source": [
    "Make sure that you understand why the parse probabilities are the way they are. Call over a staff member for a quick check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f562fee",
   "metadata": {
    "colab_type": "text",
    "id": "q0LrzA8LvY0P"
   },
   "source": [
    "# Estimating rule probabilities from a corpus\n",
    "\n",
    "In the previous section, you received a CFG augmented with rule probabilities that were arbitrarily stipulated. But where should rule probabilities come from? One way to generate rule probabilites is to learn them from a training corpus. \n",
    "\n",
    "In this section you will use a toy corpus of sentences parsed according to the lexicalized grammar to generate maximum likelihood estimates of rule probabilities by counting the number of occurrences of a rule used in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9f24ad19",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCNGAEmtJkl3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(S (S_NUM (NUM seven)))', '(S (S_ADD (S_NUM (NUM one)) (ADD plus) (S_NUM (NUM two))))', '(S (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM three))))', '(S (S_ADD (S_NUM (NUM two)) (ADD plus) (S_MULT (S_NUM (NUM six)) (MULT times) (S_NUM (NUM one)))))', '(S (S_ADD (S_ADD (S_NUM (NUM eight)) (ADD plus) (S_NUM (NUM three))) (ADD plus) (S_NUM (NUM seven))))', '(S (S_ADD (S_NUM (NUM two)) (ADD plus) (S_MULT (S_NUM (NUM three)) (MULT times) (S_NUM (NUM four)))))', '(S (S_MULT (S_MULT (S_NUM (NUM eight)) (MULT times) (S_NUM (NUM four))) (MULT times) (S_NUM (NUM two))))', '(S (S_ADD (S_MULT (S_NUM (NUM five)) (MULT times) (S_NUM (NUM two))) (ADD plus) (S_NUM (NUM one))))', '(S (S_ADD (S_NUM (NUM five)) (ADD plus) (S_MULT (S_NUM (NUM one)) (MULT times) (S_NUM (NUM four)))))', '(S (S_ADD (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM three))) (ADD plus) (S_NUM (NUM four))))', '(S (S_ADD (S_NUM (NUM ten)) (ADD plus) (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM three)))))', '(S (S_ADD (S_MULT (S_NUM (NUM four)) (MULT times) (S_NUM (NUM three))) (ADD plus) (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM one)))))', '(S (S_ADD (S_ADD (S_NUM (NUM four)) (ADD plus) (S_MULT (S_NUM (NUM three)) (MULT times) (S_NUM (NUM two)))) (ADD plus) (S_NUM (NUM one))))']\n"
     ]
    }
   ],
   "source": [
    "## The raw corpus, before splitting into separate phrases\n",
    "corpus_raw = \"\"\"\n",
    "    # seven\n",
    "    (S (S_NUM (NUM seven)))\n",
    "    # one plus two\n",
    "    (S (S_ADD (S_NUM (NUM one)) (ADD plus) (S_NUM (NUM two))))\n",
    "    # two times three\n",
    "    (S (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM three))))\n",
    "    # two plus six times one\n",
    "    (S (S_ADD (S_NUM (NUM two)) (ADD plus) (S_MULT (S_NUM (NUM six)) (MULT times) (S_NUM (NUM one)))))\n",
    "    # eight plus three plus seven\n",
    "    (S (S_ADD (S_ADD (S_NUM (NUM eight)) (ADD plus) (S_NUM (NUM three))) (ADD plus) (S_NUM (NUM seven))))\n",
    "    # two plus three times four\n",
    "    (S (S_ADD (S_NUM (NUM two)) (ADD plus) (S_MULT (S_NUM (NUM three)) (MULT times) (S_NUM (NUM four)))))\n",
    "    # eight times four times two\n",
    "    (S (S_MULT (S_MULT (S_NUM (NUM eight)) (MULT times) (S_NUM (NUM four))) (MULT times) (S_NUM (NUM two))))\n",
    "    # five times two plus one\n",
    "    (S (S_ADD (S_MULT (S_NUM (NUM five)) (MULT times) (S_NUM (NUM two))) (ADD plus) (S_NUM (NUM one))))\n",
    "    # five plus one times four\n",
    "    (S (S_ADD (S_NUM (NUM five)) (ADD plus) (S_MULT (S_NUM (NUM one)) (MULT times) (S_NUM (NUM four)))))\n",
    "    # two times three plus four\n",
    "    (S (S_ADD (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM three))) (ADD plus) (S_NUM (NUM four))))\n",
    "    # ten plus two times three\n",
    "    (S (S_ADD (S_NUM (NUM ten)) (ADD plus) (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM three)))))\n",
    "    # four times three plus two times one\n",
    "    (S (S_ADD (S_MULT (S_NUM (NUM four)) (MULT times) (S_NUM (NUM three))) (ADD plus) (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM one)))))\n",
    "    # four plus three times two plus one\n",
    "    (S (S_ADD (S_ADD (S_NUM (NUM four)) (ADD plus) (S_MULT (S_NUM (NUM three)) (MULT times) (S_NUM (NUM two)))) (ADD plus) (S_NUM (NUM one))))\n",
    "\"\"\"\n",
    "\n",
    "def corpus_from_string(raw):\n",
    "  \"\"\"Return a corpus as a list of sentences.\n",
    "  \n",
    "  The `raw` corpus is split at newlines, trimmed of whitespace, \n",
    "  and comment lines and blank lines are eliminated.\n",
    "  \"\"\"\n",
    "  return list(filter(lambda x: x != '' and x[0] != '#', \n",
    "                     map(lambda sent: sent.strip(),\n",
    "                         raw.split('\\n'))))\n",
    "\n",
    "## The processed corpus we'll use\n",
    "corpus = corpus_from_string(corpus_raw)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f988cbcd",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "ep4DSx_F2Za3"
   },
   "source": [
    "Recall that for the rule probabilities to define a valid probability distibution, the following needs to hold\n",
    "$$\\sum_{A \\to \\beta \\in G} \\Prob(\\beta \\given A) = 1$$\n",
    "where $G$ is the set of productions.\n",
    "\n",
    "In order to get an estimate for each production probability, we can count the number of occurrences of the production, normalizing by the number of occurrences of all productions with the same right-hand side.\n",
    "\n",
    "\\begin{align}\n",
    "\\Prob(\\beta \\given A) \n",
    "  &= \\frac{\\cnt{A \\to \\beta}}{\\sum_{\\beta'} \\cnt{A \\to \\beta'}} \\\\\n",
    "  &= \\frac{\\cnt{A \\to \\beta}}{\\cnt{A}}\n",
    "\\end{align}\n",
    "\n",
    "We will define three functions: \n",
    "\n",
    "1. `rule_counter` - accepts a list of sentences and returns a dictionary of rule counts (where the key is the NLTK CFG production (defined by the lhs and rhs) and the value is the number of rule occurrences)\n",
    "2. `lhs_counter` - accepts a list of sentences and returns a dictionary of lhs counts (where the key is the lhs nonterminal and the value is the count of that nonterminal's occurences as a lhs)\n",
    "3. `rule_probs` - accepts a list of sentences and returns a dictionary of rule probabilities (where the key is the production and the value is the rule probability).\n",
    "\n",
    "Implement these functions as specified above.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: probs_from_corpus\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c5dbaec8",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWRrTwp-wZOu"
   },
   "outputs": [],
   "source": [
    "#TODO \n",
    "def rule_counter(sentence_list):\n",
    "    d = defaultdict(int)\n",
    "    for sentence in sentence_list:\n",
    "        for rule in nltk.Tree.fromstring(sentence).productions():\n",
    "            d[rule] += 1\n",
    "    return d       \n",
    "\n",
    "#TODO\n",
    "def lhs_counter(sentence_list):\n",
    "    d = defaultdict(int)\n",
    "    for sentence in sentence_list:\n",
    "        for rule in nltk.Tree.fromstring(sentence).productions():\n",
    "            d[rule.lhs()] += 1\n",
    "    \n",
    "    return d\n",
    "\n",
    "#TODO\n",
    "def rule_probs(sentence_list):\n",
    "    ruleDict = rule_counter(sentence_list)\n",
    "    lhsDict = lhs_counter(sentence_list)\n",
    "    print(ruleDict)\n",
    "    print(lhsDict)\n",
    "    d = {}\n",
    "    for sentence in sentence_list:\n",
    "        for rule in nltk.Tree.fromstring(sentence).productions():\n",
    "            d[rule] = ruleDict[rule] / lhsDict[rule.lhs()]\n",
    "            #keyCount += 1\n",
    "    print(d)\n",
    "    return d\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8d9c4634",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"probs_from_corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6292ebd4",
   "metadata": {
    "colab_type": "text",
    "id": "sMEdd-KSg3J5"
   },
   "source": [
    "Now we can use the `rules_prob` function you wrote to get the rule probabilities from our corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c96e1d17",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q0TCm-8vgOAR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {S -> S_NUM: 1, S_NUM -> NUM: 37, NUM -> 'seven': 2, S -> S_ADD: 10, S_ADD -> S_NUM ADD S_NUM: 2, NUM -> 'one': 6, ADD -> 'plus': 12, NUM -> 'two': 10, S -> S_MULT: 2, S_MULT -> S_NUM MULT S_NUM: 11, MULT -> 'times': 12, NUM -> 'three': 7, S_ADD -> S_NUM ADD S_MULT: 5, NUM -> 'six': 1, S_ADD -> S_ADD ADD S_NUM: 2, NUM -> 'eight': 2, NUM -> 'four': 6, S_MULT -> S_MULT MULT S_NUM: 1, S_ADD -> S_MULT ADD S_NUM: 2, NUM -> 'five': 2, NUM -> 'ten': 1, S_ADD -> S_MULT ADD S_MULT: 1})\n",
      "defaultdict(<class 'int'>, {S: 13, S_NUM: 37, NUM: 37, S_ADD: 12, ADD: 12, S_MULT: 12, MULT: 12})\n",
      "{S -> S_NUM: 0.07692307692307693, S_NUM -> NUM: 1.0, NUM -> 'seven': 0.05405405405405406, S -> S_ADD: 0.7692307692307693, S_ADD -> S_NUM ADD S_NUM: 0.16666666666666666, NUM -> 'one': 0.16216216216216217, ADD -> 'plus': 1.0, NUM -> 'two': 0.2702702702702703, S -> S_MULT: 0.15384615384615385, S_MULT -> S_NUM MULT S_NUM: 0.9166666666666666, MULT -> 'times': 1.0, NUM -> 'three': 0.1891891891891892, S_ADD -> S_NUM ADD S_MULT: 0.4166666666666667, NUM -> 'six': 0.02702702702702703, S_ADD -> S_ADD ADD S_NUM: 0.16666666666666666, NUM -> 'eight': 0.05405405405405406, NUM -> 'four': 0.16216216216216217, S_MULT -> S_MULT MULT S_NUM: 0.08333333333333333, S_ADD -> S_MULT ADD S_NUM: 0.16666666666666666, NUM -> 'five': 0.05405405405405406, NUM -> 'ten': 0.02702702702702703, S_ADD -> S_MULT ADD S_MULT: 0.08333333333333333}\n",
      "{ADD -> 'plus': 1.0,\n",
      " MULT -> 'times': 1.0,\n",
      " NUM -> 'eight': 0.05405405405405406,\n",
      " NUM -> 'five': 0.05405405405405406,\n",
      " NUM -> 'four': 0.16216216216216217,\n",
      " NUM -> 'one': 0.16216216216216217,\n",
      " NUM -> 'seven': 0.05405405405405406,\n",
      " NUM -> 'six': 0.02702702702702703,\n",
      " NUM -> 'ten': 0.02702702702702703,\n",
      " NUM -> 'three': 0.1891891891891892,\n",
      " NUM -> 'two': 0.2702702702702703,\n",
      " S -> S_ADD: 0.7692307692307693,\n",
      " S -> S_MULT: 0.15384615384615385,\n",
      " S -> S_NUM: 0.07692307692307693,\n",
      " S_ADD -> S_ADD ADD S_NUM: 0.16666666666666666,\n",
      " S_ADD -> S_MULT ADD S_MULT: 0.08333333333333333,\n",
      " S_ADD -> S_MULT ADD S_NUM: 0.16666666666666666,\n",
      " S_ADD -> S_NUM ADD S_MULT: 0.4166666666666667,\n",
      " S_ADD -> S_NUM ADD S_NUM: 0.16666666666666666,\n",
      " S_MULT -> S_MULT MULT S_NUM: 0.08333333333333333,\n",
      " S_MULT -> S_NUM MULT S_NUM: 0.9166666666666666,\n",
      " S_NUM -> NUM: 1.0}\n"
     ]
    }
   ],
   "source": [
    "probs_from_corpus = rule_probs(corpus)\n",
    "pprint(probs_from_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6307ece",
   "metadata": {
    "colab_type": "text",
    "id": "VofTcEId8Y-n"
   },
   "source": [
    "Observe that the probabilities of the two rules `S_ADD -> S_NUM ADD S_MULT` and `S_MULT -> S_ADD MULT S_NUM` are now different from each other. (They were both the same in the previous grammar, since you made the probabilities as uniform as possible.)\n",
    "\n",
    "NLTK allows us to infer a probabilistic grammar from a parsed corpus like this one using [`nltk.induce_pcfg`](https://www.nltk.org/api/nltk.grammar.html#nltk.grammar.induce_pcfg). Let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b0d2cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 22 productions (start state = S)\n",
      "    S -> S_NUM [0.0769231]\n",
      "    S_NUM -> NUM [1.0]\n",
      "    NUM -> 'seven' [0.0540541]\n",
      "    S -> S_ADD [0.769231]\n",
      "    S_ADD -> S_NUM ADD S_NUM [0.166667]\n",
      "    NUM -> 'one' [0.162162]\n",
      "    ADD -> 'plus' [1.0]\n",
      "    NUM -> 'two' [0.27027]\n",
      "    S -> S_MULT [0.153846]\n",
      "    S_MULT -> S_NUM MULT S_NUM [0.916667]\n",
      "    MULT -> 'times' [1.0]\n",
      "    NUM -> 'three' [0.189189]\n",
      "    S_ADD -> S_NUM ADD S_MULT [0.416667]\n",
      "    NUM -> 'six' [0.027027]\n",
      "    S_ADD -> S_ADD ADD S_NUM [0.166667]\n",
      "    NUM -> 'eight' [0.0540541]\n",
      "    NUM -> 'four' [0.162162]\n",
      "    S_MULT -> S_MULT MULT S_NUM [0.0833333]\n",
      "    S_ADD -> S_MULT ADD S_NUM [0.166667]\n",
      "    NUM -> 'five' [0.0540541]\n",
      "    NUM -> 'ten' [0.027027]\n",
      "    S_ADD -> S_MULT ADD S_MULT [0.0833333]\n"
     ]
    }
   ],
   "source": [
    "def flatten(l):\n",
    "    return sum(l, [])\n",
    "    \n",
    "def pcfg_from_trees(trees):\n",
    "    return nltk.induce_pcfg(nltk.Nonterminal('S'), \n",
    "                            flatten([nltk.Tree.fromstring(tree).productions() \n",
    "                                     for tree in trees]))\n",
    "\n",
    "induced_pcfg = pcfg_from_trees(corpus)\n",
    "\n",
    "print(induced_pcfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce07bf7e",
   "metadata": {},
   "source": [
    "We'll use NLTK's implementation of the probabilistic CKY algorithm ([`nltk.ViterbiParser`](https://www.nltk.org/api/nltk.parse.viterbi.html#nltk.parse.viterbi.ViterbiParser)) to generate the best parse for some strings according to this induced PCFG. (You'll implement this yourself in lab 3-4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "53e3435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "induced_parser = nltk.ViterbiParser(induced_pcfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b240cc5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Use this parser to parse the `example` phrase \"two plus three times four\" from above. Which parse does it return? Do you understand why?\n",
    "\n",
    "> Be careful. The parser returns a Python generator of the parses, not a list. You can't use the generator twice, so you should save the `induced_grammar_parses` as a list constructed from the generator object to pass all of the tests.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: induced_grammar_parses\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cada446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - parse `example` using `induced_parser`\n",
    "induced_grammar_parses = list(induced_parser.parse(example.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0d13e438",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"induced_grammar_parses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "23556380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of parse tree 1 is 2.44e-03\n",
      "             S               \n",
      "             |                \n",
      "           S_ADD             \n",
      "   __________|_____           \n",
      "  |    |         S_MULT      \n",
      "  |    |      _____|______    \n",
      "S_NUM  |   S_NUM   |    S_NUM\n",
      "  |    |     |     |      |   \n",
      " NUM  ADD   NUM   MULT   NUM \n",
      "  |    |     |     |      |   \n",
      " two  plus three times   four\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, tree in enumerate(induced_grammar_parses):\n",
    "    print(f'Probability of parse tree {i+1} is '\n",
    "          f'{parse_probability(tree, induced_pcfg):1.2e}')\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7bed7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "How many parses there are for the expression \"three plus nine plus two\" according to the induced PCFG? Set the variable in the next cell accordingly.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: parse_count_2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "65270dfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grammar does not cover some of the input words: \"'nine'\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/09/v1n7m90x4x19d0b5zn46swr80000gn/T/ipykernel_17441/4157138371.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"three plus nine plus two\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minduced_grammar_parses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minduced_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minduced_grammar_parses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     print(f'Probability of parse tree {i+1} is '\n\u001b[1;32m      5\u001b[0m           f'{parse_probability(tree, induced_pcfg):1.2e}')\n",
      "\u001b[0;32m~/miniconda/envs/cs187/lib/python3.8/site-packages/nltk/parse/viterbi.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_coverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# The most likely constituent table.  This table specifies the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/cs187/lib/python3.8/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mcheck_coverage\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    678\u001b[0m                 \u001b[0;34m\"Grammar does not cover some of the \"\u001b[0m \u001b[0;34m\"input words: %r.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Grammar does not cover some of the input words: \"'nine'\"."
     ]
    }
   ],
   "source": [
    "example = \"three plus nine plus two\"\n",
    "induced_grammar_parses = list(induced_parser.parse(example.split()))\n",
    "for i, tree in enumerate(induced_grammar_parses):\n",
    "    print(f'Probability of parse tree {i+1} is '\n",
    "          f'{parse_probability(tree, induced_pcfg):1.2e}')\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eaab2ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "example2_parse_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e41c7b7b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"parse_count_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88145f12",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** You undoubtedly obtained a number of parses for this second example that didn't seem appropriate. With a _single word_, what technique that you've learned would be appropriate to solve this problem.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_debrief\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07734ea0",
   "metadata": {},
   "source": [
    "smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fea15c",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "h2F-sJGitFgs"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** The example that we provided of an ambiguity in arithmetic expressions is admittedly quite artificial. Can you think of other (more natural) examples, in natural language or elsewhere, where this phenomenon might occur?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_other_examples\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274c9ed8",
   "metadata": {},
   "source": [
    "Ambiguity in natural language also occurs when referring to multiple subjects that are doing less than the number of subjects actions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2637ad0d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "# Lab debrief – for consensus submission only\n",
    "\n",
    "**Question:** We're interested in any thoughts your group has about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on include the following: \n",
    "\n",
    "* Was the lab too long or too short?\n",
    "* Were the readings appropriate for the lab? \n",
    "* Was it clear (at least after you completed the lab) what the points of the exercises were? \n",
    "* Are there additions or changes you think would make the lab better?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_debrief\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0458afdb",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b4b43e",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# End of Lab 3-3 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c649f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc1b5c5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab3-3_op3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "title": "CS187 Lab 3-3: Probabilistic context-free grammars"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
